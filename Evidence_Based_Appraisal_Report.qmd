---
title: "Evidence-Based Appraisal Report"
subtitle: "Statistical Market Analysis"
author: "`r params$AppraiserName`"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc-depth: 3
    theme: cosmo
    code-fold: true
  pdf:
    toc: true
    toc-depth: 2
    geometry: margin=1in
params:
  # Subject Property
  Address: "528 S Taper Ave"
  City: "Compton"
  State: "CA"
  Zip: "90220"
  County: "Los Angeles"
  
  # Property Characteristics
  LivingArea: 951
  Bedrooms: 2
  Bathrooms: 1
  YearBuilt: 1950
  LotSize: 5500
  GarageSpaces: 1
  PropertyType: "Single Family Residence"
  
  # Appraisal Details
  AppraiserName: "Craig Gilbert"
  FileNumber: "25-060_2025"
  ClientName: "Katherine Hinton, esq"
  ClientCompany: "Masatani Soray Law"
  IntendedUse: "Litigation Support"
  DateEffective: "2025-11-01"
  DateInspection: "2025-11-01"
  
  # Analysis Parameters
  DataFile: "2025 Sold data for Stats_Full (30).csv"
  ConfigFile: "market_analysis_inputs.json"
  ValidationFile: "validation_info.json"
  
  # Market Filters
  MinLivingArea: 700
  MaxLivingArea: 1500
  MinBedrooms: 2
  MaxBedrooms: 4
  MaxDaysOld: 180
  
  # Opinion of Value
  EstimatedValue: 250000
  ValueRangeLow: 240000
  ValueRangeHigh: 260000
---

# Executive Summary

**Subject Property:** `r params$Address`, `r params$City`, `r params$State` `r params$Zip`

**Property Type:** `r params$PropertyType`

**Effective Date:** `r params$DateEffective`

**Client:** `r params$ClientName`, `r params$ClientCompany`

**Intended Use:** `r params$IntendedUse`

**Opinion of Market Value:** `r scales::dollar(params$EstimatedValue)`

**Value Range:** `r scales::dollar(params$ValueRangeLow)` - `r scales::dollar(params$ValueRangeHigh)`

---

# Evidence-Based Valuation Methodology

This appraisal employs an **Evidence-Based Valuation (EBV)** approach, which analyzes the entire market population rather than relying on a small sample of comparable sales. This methodology provides:

- **Statistical rigor** through analysis of all relevant market transactions
- **Market trend quantification** using linear regression and time series analysis
- **Transparent data coverage** with validity metrics and confidence intervals
- **Visual market analytics** showing price distributions, trends, and correlations
- **Machine learning validation** using Random Forest and other predictive models

The analysis incorporates sold properties, active listings, pending sales, and market conditions to provide a comprehensive market value opinion.

---

```{r setup, include=FALSE}
#| label: setup-r
#| include: false

# Load R packages
library(tidyverse)
library(lubridate)
library(scales)
library(gt)
library(ggthemes)
library(patchwork)
library(reticulate)
library(jsonlite)

# Configure options
options(scipen = 999)
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6,
  dpi = 300
)
```

```{python setup-python}
#| label: setup-python
#| include: false

# Load Python packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.ticker import FuncFormatter
import seaborn as sns
from scipy import stats
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

# Currency formatter
def currency_formatter(x, pos):
    return f'${x:,.0f}'

# Date formatter
def date_formatter(x, pos):
    return mdates.num2date(x).strftime('%b %d')
```

---

# Subject Property Description

```{r subject-table}
#| label: subject-table

# Create subject property summary
subject_data <- tibble(
  Characteristic = c(
    "Address",
    "City, State, ZIP",
    "County",
    "Property Type",
    "Living Area (SF)",
    "Bedrooms",
    "Bathrooms",
    "Year Built",
    "Lot Size (SF)",
    "Garage",
    "Effective Date"
  ),
  Details = c(
    params$Address,
    paste0(params$City, ", ", params$State, " ", params$Zip),
    params$County,
    params$PropertyType,
    format(params$LivingArea, big.mark = ","),
    params$Bedrooms,
    params$Bathrooms,
    params$YearBuilt,
    format(params$LotSize, big.mark = ","),
    paste(params$GarageSpaces, "car"),
    params$DateEffective
  )
)

# Display as formatted table
subject_data %>%
  gt() %>%
  tab_header(
    title = "Subject Property Summary"
  ) %>%
  cols_label(
    Characteristic = "Characteristic",
    Details = "Details"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_options(
    table.width = pct(100),
    table.font.size = 12
  )
```

---

# Market Data Collection

```{r load-data}
#| label: load-data

# Load sales data
sales_data <- read_csv(params$DataFile, show_col_types = FALSE) %>%
  janitor::clean_names()

# Standardize column names (handle variations in MLS exports)
sales_data <- sales_data %>%
  rename_with(~ case_when(
    str_detect(., "(?i)close.*date") ~ "sale_date",
    str_detect(., "(?i)close.*price") ~ "sale_price",
    str_detect(., "(?i)living.*area") ~ "living_area",
    str_detect(., "(?i)bedroom") ~ "bedrooms",
    str_detect(., "(?i)bathroom.*total.*integer") ~ "bathrooms",
    str_detect(., "(?i)year.*built") ~ "year_built",
    str_detect(., "(?i)lot.*size.*square") ~ "lot_size",
    str_detect(., "(?i)garage.*space") ~ "garage_spaces",
    str_detect(., "(?i)days.*market") ~ "dom",
    str_detect(., "(?i)cumulative.*days") ~ "cdom",
    str_detect(., "(?i)street.*name") ~ "street_name",
    str_detect(., "(?i)street.*number") ~ "street_number",
    TRUE ~ .
  ))

# Clean and filter data
sales_clean <- sales_data %>%
  filter(
    !is.na(sale_date),
    !is.na(sale_price),
    !is.na(living_area),
    sale_price > 0,
    living_area > 0
  ) %>%
  mutate(
    sale_date = mdy(sale_date),
    days_from_effective = as.numeric(ymd(params$DateEffective) - sale_date),
    price_per_sf = sale_price / living_area
  ) %>%
  filter(
    days_from_effective >= 0,
    days_from_effective <= params$MaxDaysOld,
    living_area >= params$MinLivingArea,
    living_area <= params$MaxLivingArea
  )

# Summary statistics
n_sales <- nrow(sales_clean)
date_range <- range(sales_clean$sale_date)
coverage_days <- as.numeric(ymd(params$DateEffective) - min(sales_clean$sale_date))
coverage_months <- coverage_days / 30.44

cat("Market Data Summary:\n")
cat("Total Sales Analyzed:", n_sales, "\n")
cat("Date Range:", format(date_range[1], "%B %d, %Y"), "to", format(date_range[2], "%B %d, %Y"), "\n")
cat("Data Coverage:", round(coverage_months, 1), "months\n")
cat("Living Area Range:", min(sales_clean$living_area), "-", max(sales_clean$living_area), "SF\n")
```

```{python load-config}
#| label: load-config

# Load configuration and validation results if available
try:
    with open(r.params['ValidationFile'], 'r') as f:
        validation_info = json.load(f)
    
    trend_results = validation_info.get('trend_results', {})
    monthly_trend_pct = trend_results.get('monthly_price_change_pct', 0)
    daily_change = trend_results.get('daily_price_change', 0)
    r_squared = trend_results.get('r_squared', 0)
    market_trend = trend_results.get('market_trend', 'STABLE')
    
    print(f"Trend Analysis Loaded:")
    print(f"  Monthly Trend: {monthly_trend_pct:.2f}%")
    print(f"  Daily Change: ${daily_change:.2f}")
    print(f"  R² Value: {r_squared:.4f}")
    print(f"  Market Direction: {market_trend}")
except:
    print("Validation file not found - will compute trends from data")
    validation_info = None
```

---

# Market Area Analysis

```{r market-area-stats}
#| label: market-area-stats

# Calculate market statistics by time period
market_stats <- sales_clean %>%
  mutate(
    period = case_when(
      days_from_effective <= 30 ~ "0-1 months",
      days_from_effective <= 60 ~ "1-2 months",
      days_from_effective <= 90 ~ "2-3 months",
      days_from_effective <= 120 ~ "3-4 months",
      days_from_effective <= 150 ~ "4-5 months",
      TRUE ~ "5-6 months"
    )
  ) %>%
  group_by(period) %>%
  summarise(
    n_sales = n(),
    median_price = median(sale_price),
    mean_price = mean(sale_price),
    median_price_sf = median(price_per_sf),
    mean_price_sf = mean(price_per_sf),
    min_price = min(sale_price),
    max_price = max(sale_price),
    sd_price = sd(sale_price),
    .groups = 'drop'
  )

# Display statistics table
market_stats %>%
  gt() %>%
  tab_header(
    title = "Market Statistics by Time Period"
  ) %>%
  fmt_number(
    columns = c(median_price, mean_price, min_price, max_price, sd_price),
    decimals = 0
  ) %>%
  fmt_currency(
    columns = c(median_price, mean_price, min_price, max_price, sd_price),
    decimals = 0
  ) %>%
  fmt_currency(
    columns = c(median_price_sf, mean_price_sf),
    decimals = 2
  ) %>%
  cols_label(
    period = "Time Period",
    n_sales = "N",
    median_price = "Median Price",
    mean_price = "Mean Price",
    median_price_sf = "Median $/SF",
    mean_price_sf = "Mean $/SF",
    min_price = "Min",
    max_price = "Max",
    sd_price = "Std Dev"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  )
```

```{r market-boxplots, fig.height=8}
#| label: market-boxplots
#| fig.height: 8

# Create boxplot visualizations
p1 <- sales_clean %>%
  ggplot(aes(x = "", y = sale_price)) +
  geom_boxplot(fill = "#3498db", alpha = 0.6) +
  geom_hline(yintercept = params$EstimatedValue, 
             color = "red", linetype = "dashed", size = 1.2) +
  annotate("text", x = 1.3, y = params$EstimatedValue,
           label = paste("Subject:", dollar(params$EstimatedValue)),
           color = "red", fontface = "bold") +
  scale_y_continuous(labels = dollar_format()) +
  labs(
    title = "Sale Price Distribution",
    subtitle = "Subject position shown in red",
    x = NULL,
    y = "Sale Price"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_blank())

p2 <- sales_clean %>%
  ggplot(aes(x = "", y = price_per_sf)) +
  geom_boxplot(fill = "#2ecc71", alpha = 0.6) +
  geom_hline(yintercept = params$EstimatedValue / params$LivingArea,
             color = "red", linetype = "dashed", size = 1.2) +
  annotate("text", x = 1.3, y = params$EstimatedValue / params$LivingArea,
           label = paste("Subject:", dollar(params$EstimatedValue / params$LivingArea)),
           color = "red", fontface = "bold") +
  scale_y_continuous(labels = dollar_format()) +
  labs(
    title = "Price Per SF Distribution",
    x = NULL,
    y = "Price per SF"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_blank())

# Combine plots
p1 / p2
```

---

# Statistical Analysis - Python Charts

## Chart 1: Sale Price Trend with Linear Regression

```{python chart1-price-trend}
#| label: chart1-price-trend
#| fig-width: 10
#| fig-height: 6

# Convert R data to Python
sales_py = r.sales_clean.copy()
sales_py['sale_date'] = pd.to_datetime(sales_py['sale_date'])
sales_py['days_from_effective'] = (pd.to_datetime(r.params['DateEffective']) - sales_py['sale_date']).dt.days

# Sort by date
sales_py = sales_py.sort_values('sale_date')

# Calculate linear regression
x = sales_py['days_from_effective'].values
y = sales_py['sale_price'].values
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
line = slope * x + intercept

# Create plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.scatter(sales_py['sale_date'], sales_py['sale_price'], 
           alpha=0.6, s=100, c='#3498db', edgecolors='black', linewidth=0.5)
ax.plot(sales_py['sale_date'], line, 'r-', linewidth=2, label='Trend Line')

# Format axes
ax.yaxis.set_major_formatter(FuncFormatter(currency_formatter))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))
plt.xticks(rotation=45)

# Add grid
ax.grid(True, alpha=0.3, linestyle='--')

# Calculate daily and monthly changes
daily_change = -slope  # Negative because days_from_effective decreases toward present
monthly_change_pct = (daily_change * 30.44 / np.mean(y)) * 100

# Add statistics box
stats_text = f'Linear Regression\n'
stats_text += f'R² = {r_value**2:.4f}\n'
stats_text += f'Daily Change: ${daily_change:.2f}\n'
stats_text += f'Monthly Trend: {monthly_change_pct:+.2f}%\n'
stats_text += f'N = {len(sales_py)}'

ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

# Labels
ax.set_xlabel('Sale Date', fontsize=12, fontweight='bold')
ax.set_ylabel('Sale Price', fontsize=12, fontweight='bold')
ax.set_title('Sale Price Trend Analysis', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='lower right')

plt.tight_layout()
plt.show()

# Print regression equation
print(f"\nRegression Equation: Price = ${intercept:,.0f} - ${abs(slope):.2f} × (days from present)")
print(f"Market is {'INCREASING' if daily_change > 0 else 'DECREASING' if daily_change < 0 else 'STABLE'}")
```

## Chart 2: Price Per SF Trend

```{python chart2-price-sf-trend}
#| label: chart2-price-sf-trend
#| fig-width: 10
#| fig-height: 6

# Calculate regression for price per SF
y_psf = sales_py['price_per_sf'].values
slope_psf, intercept_psf, r_value_psf, p_value_psf, std_err_psf = stats.linregress(x, y_psf)
line_psf = slope_psf * x + intercept_psf

# Create plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.scatter(sales_py['sale_date'], sales_py['price_per_sf'],
           alpha=0.6, s=100, c='#2ecc71', edgecolors='black', linewidth=0.5)
ax.plot(sales_py['sale_date'], line_psf, 'r-', linewidth=2, label='Trend Line')

# Format axes
ax.yaxis.set_major_formatter(FuncFormatter(currency_formatter))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))
plt.xticks(rotation=45)

# Add grid
ax.grid(True, alpha=0.3, linestyle='--')

# Statistics
daily_change_psf = -slope_psf
monthly_change_pct_psf = (daily_change_psf * 30.44 / np.mean(y_psf)) * 100

stats_text = f'Linear Regression\n'
stats_text += f'R² = {r_value_psf**2:.4f}\n'
stats_text += f'Daily Change: ${daily_change_psf:.2f}\n'
stats_text += f'Monthly Trend: {monthly_change_pct_psf:+.2f}%\n'
stats_text += f'N = {len(sales_py)}'

ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

ax.set_xlabel('Sale Date', fontsize=12, fontweight='bold')
ax.set_ylabel('Price per SF', fontsize=12, fontweight='bold')
ax.set_title('Price Per SF Trend Analysis', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='lower right')

plt.tight_layout()
plt.show()
```

## Chart 3: Sale Price Distribution

```{python chart3-price-distribution}
#| label: chart3-price-distribution
#| fig-width: 10
#| fig-height: 6

fig, ax = plt.subplots(figsize=(10, 6))

# Create histogram
n, bins, patches = ax.hist(sales_py['sale_price'], bins=15, 
                            color='#3498db', alpha=0.7, edgecolor='black')

# Add mean and median lines
mean_price = sales_py['sale_price'].mean()
median_price = sales_py['sale_price'].median()

ax.axvline(mean_price, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_price:,.0f}')
ax.axvline(median_price, color='green', linestyle='--', linewidth=2, label=f'Median: ${median_price:,.0f}')

# Add subject value line
ax.axvline(r.params['EstimatedValue'], color='orange', linestyle=':', linewidth=2.5, 
           label=f'Subject: ${r.params["EstimatedValue"]:,.0f}')

# Format
ax.xaxis.set_major_formatter(FuncFormatter(currency_formatter))
ax.grid(True, alpha=0.3, axis='y')

# Statistics text
stats_text = f'N = {len(sales_py)}\n'
stats_text += f'Mean = ${mean_price:,.0f}\n'
stats_text += f'Median = ${median_price:,.0f}\n'
stats_text += f'Std Dev = ${sales_py["sale_price"].std():,.0f}\n'
stats_text += f'Range = ${sales_py["sale_price"].min():,.0f} - ${sales_py["sale_price"].max():,.0f}'

ax.text(0.98, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top', horizontalalignment='right',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

ax.set_xlabel('Sale Price', fontsize=12, fontweight='bold')
ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')
ax.set_title('Sale Price Distribution', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='upper left')

plt.tight_layout()
plt.show()
```

## Chart 4: Price Per SF Distribution

```{python chart4-pricesf-distribution}
#| label: chart4-pricesf-distribution
#| fig-width: 10
#| fig-height: 6

fig, ax = plt.subplots(figsize=(10, 6))

# Create histogram
n, bins, patches = ax.hist(sales_py['price_per_sf'], bins=15,
                            color='#2ecc71', alpha=0.7, edgecolor='black')

# Add mean and median lines
mean_psf = sales_py['price_per_sf'].mean()
median_psf = sales_py['price_per_sf'].median()

ax.axvline(mean_psf, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_psf:.2f}')
ax.axvline(median_psf, color='green', linestyle='--', linewidth=2, label=f'Median: ${median_psf:.2f}')

# Subject value
subject_psf = r.params['EstimatedValue'] / r.params['LivingArea']
ax.axvline(subject_psf, color='orange', linestyle=':', linewidth=2.5,
           label=f'Subject: ${subject_psf:.2f}')

# Format
ax.xaxis.set_major_formatter(FuncFormatter(currency_formatter))
ax.grid(True, alpha=0.3, axis='y')

# Statistics
stats_text = f'N = {len(sales_py)}\n'
stats_text += f'Mean = ${mean_psf:.2f}\n'
stats_text += f'Median = ${median_psf:.2f}\n'
stats_text += f'Std Dev = ${sales_py["price_per_sf"].std():.2f}\n'
stats_text += f'Range = ${sales_py["price_per_sf"].min():.2f} - ${sales_py["price_per_sf"].max():.2f}'

ax.text(0.98, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top', horizontalalignment='right',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

ax.set_xlabel('Price per SF', fontsize=12, fontweight='bold')
ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')
ax.set_title('Price Per SF Distribution', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='upper left')

plt.tight_layout()
plt.show()
```

## Chart 5: Living Area vs Sale Price with Regression

```{python chart5-scatter-regression}
#| label: chart5-scatter-regression
#| fig-width: 10
#| fig-height: 6

# Calculate regression
x_area = sales_py['living_area'].values
y_price = sales_py['sale_price'].values
slope_area, intercept_area, r_value_area, p_value_area, std_err_area = stats.linregress(x_area, y_price)
line_area = slope_area * x_area + intercept_area

# Create plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.scatter(sales_py['living_area'], sales_py['sale_price'],
           alpha=0.6, s=100, c='#9b59b6', edgecolors='black', linewidth=0.5)
ax.plot(sales_py['living_area'], line_area, 'r-', linewidth=2, label='Regression Line')

# Add subject property
ax.scatter([r.params['LivingArea']], [r.params['EstimatedValue']],
           s=300, c='orange', marker='*', edgecolors='black', linewidth=2,
           label='Subject Property', zorder=5)

# Format
ax.yaxis.set_major_formatter(FuncFormatter(currency_formatter))
ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: f'{x:,.0f}'))
ax.grid(True, alpha=0.3)

# Regression equation and stats
stats_text = f'Regression Equation:\n'
stats_text += f'Price = ${intercept_area:,.0f} + ${slope_area:.2f} × SF\n'
stats_text += f'\nR² = {r_value_area**2:.4f}\n'
stats_text += f'Marginal Value: ${slope_area:.2f}/SF\n'
stats_text += f'N = {len(sales_py)}'

ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

ax.set_xlabel('Living Area (SF)', fontsize=12, fontweight='bold')
ax.set_ylabel('Sale Price', fontsize=12, fontweight='bold')
ax.set_title('Living Area vs Sale Price with Linear Regression', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='lower right')

plt.tight_layout()
plt.show()

print(f"\nMarginal Value per Square Foot: ${slope_area:.2f}")
print(f"Base Value (intercept): ${intercept_area:,.0f}")
```

## Chart 6: Living Area Distribution

```{python chart6-area-distribution}
#| label: chart6-area-distribution
#| fig-width: 10
#| fig-height: 6

fig, ax = plt.subplots(figsize=(10, 6))

# Create histogram
n, bins, patches = ax.hist(sales_py['living_area'], bins=15,
                            color='#e74c3c', alpha=0.7, edgecolor='black')

# Add subject marker
ax.axvline(r.params['LivingArea'], color='orange', linestyle=':', linewidth=2.5,
           label=f'Subject: {r.params["LivingArea"]:,} SF')

# Statistics
mean_area = sales_py['living_area'].mean()
median_area = sales_py['living_area'].median()

ax.axvline(mean_area, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_area:,.0f} SF')
ax.axvline(median_area, color='green', linestyle='--', linewidth=2, label=f'Median: {median_area:,.0f} SF')

# Format
ax.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: f'{x:,.0f}'))
ax.grid(True, alpha=0.3, axis='y')

# Stats text
stats_text = f'N = {len(sales_py)}\n'
stats_text += f'Mean = {mean_area:,.0f} SF\n'
stats_text += f'Median = {median_area:,.0f} SF\n'
stats_text += f'Std Dev = {sales_py["living_area"].std():,.0f} SF\n'
stats_text += f'Range = {sales_py["living_area"].min():,.0f} - {sales_py["living_area"].max():,.0f} SF'

ax.text(0.98, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top', horizontalalignment='right',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

ax.set_xlabel('Living Area (SF)', fontsize=12, fontweight='bold')
ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')
ax.set_title('Living Area Distribution', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='upper right')

plt.tight_layout()
plt.show()
```

## Chart 7: Monthly Absorption Rate

```{python chart7-absorption}
#| label: chart7-absorption
#| fig-width: 10
#| fig-height: 6

# Calculate monthly sales volume
sales_py['year_month'] = sales_py['sale_date'].dt.to_period('M')
monthly_sales = sales_py.groupby('year_month').size().reset_index(name='count')
monthly_sales['year_month'] = monthly_sales['year_month'].dt.to_timestamp()

# Create bar chart
fig, ax = plt.subplots(figsize=(10, 6))
bars = ax.bar(monthly_sales['year_month'], monthly_sales['count'],
              width=20, color='#1abc9c', alpha=0.7, edgecolor='black')

# Format
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
plt.xticks(rotation=45)
ax.grid(True, alpha=0.3, axis='y')

# Calculate average absorption
avg_absorption = monthly_sales['count'].mean()
ax.axhline(avg_absorption, color='red', linestyle='--', linewidth=2,
           label=f'Average: {avg_absorption:.1f} sales/month')

# Stats
stats_text = f'Total Sales: {monthly_sales["count"].sum()}\n'
stats_text += f'Avg/Month: {avg_absorption:.1f}\n'
stats_text += f'Months: {len(monthly_sales)}\n'
stats_text += f'Min: {monthly_sales["count"].min()}\n'
stats_text += f'Max: {monthly_sales["count"].max()}'

ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
        fontsize=10, verticalalignment='top',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

ax.set_xlabel('Month', fontsize=12, fontweight='bold')
ax.set_ylabel('Number of Sales', fontsize=12, fontweight='bold')
ax.set_title('Monthly Sales Volume (Absorption Rate)', fontsize=14, fontweight='bold', pad=20)
ax.legend(loc='upper right')

plt.tight_layout()
plt.show()
```

---

# Machine Learning Validation

```{python ml-validation}
#| label: ml-validation

# Prepare features for Random Forest
feature_cols = ['living_area', 'bedrooms', 'bathrooms', 'days_from_effective']
available_features = [col for col in feature_cols if col in sales_py.columns]

# Handle missing values
ml_data = sales_py[available_features + ['sale_price']].dropna()

if len(ml_data) >= 10:  # Need minimum samples
    X = ml_data[available_features]
    y = ml_data['sale_price']
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Train Random Forest
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5)
    rf_model.fit(X_train, y_train)
    
    # Predictions
    train_score = rf_model.score(X_train, y_train)
    test_score = rf_model.score(X_test, y_test)
    
    # Feature importance
    feature_importance = pd.DataFrame({
        'Feature': available_features,
        'Importance': rf_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    # Predict subject value
    subject_features = pd.DataFrame({
        'living_area': [r.params['LivingArea']],
        'bedrooms': [r.params['Bedrooms']],
        'bathrooms': [r.params['Bathrooms']],
        'days_from_effective': [0]
    })
    
    # Only use available features
    subject_features = subject_features[[col for col in available_features]]
    rf_prediction = rf_model.predict(subject_features)[0]
    
    print("Random Forest Model Performance:")
    print(f"  Training R²: {train_score:.4f}")
    print(f"  Testing R²: {test_score:.4f}")
    print(f"\nFeature Importance:")
    for idx, row in feature_importance.iterrows():
        print(f"  {row['Feature']}: {row['Importance']:.4f}")
    print(f"\nML Predicted Value: ${rf_prediction:,.0f}")
    print(f"Appraiser Opinion: ${r.params['EstimatedValue']:,.0f}")
    print(f"Difference: ${abs(rf_prediction - r.params['EstimatedValue']):,.0f} ({abs(rf_prediction - r.params['EstimatedValue']) / r.params['EstimatedValue'] * 100:.2f}%)")
else:
    print("Insufficient data for machine learning validation")
    rf_prediction = None
```

---

# Data Coverage Validation

```{r data-coverage}
#| label: data-coverage

# Calculate data coverage metrics
coverage_summary <- tibble(
  Metric = c(
    "Number of Sales",
    "Date Range (Start)",
    "Date Range (End)",
    "Coverage Period (Days)",
    "Coverage Period (Months)",
    "Average Days on Market",
    "Median Days on Market",
    "Market Velocity"
  ),
  Value = c(
    as.character(n_sales),
    format(date_range[1], "%B %d, %Y"),
    format(date_range[2], "%B %d, %Y"),
    as.character(coverage_days),
    sprintf("%.1f", coverage_months),
    sprintf("%.0f", mean(sales_clean$dom, na.rm = TRUE)),
    sprintf("%.0f", median(sales_clean$dom, na.rm = TRUE)),
    if_else(coverage_months >= 3, "Good", if_else(coverage_months >= 1.5, "Adequate", "Limited"))
  )
)

coverage_summary %>%
  gt() %>%
  tab_header(
    title = "Data Coverage Summary"
  ) %>%
  cols_label(
    Metric = "Metric",
    Value = "Value"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  tab_style(
    style = cell_fill(color = "#d4edda"),
    locations = cells_body(rows = Metric == "Market Velocity" & Value == "Good")
  ) %>%
  tab_style(
    style = cell_fill(color = "#fff3cd"),
    locations = cells_body(rows = Metric == "Market Velocity" & Value == "Adequate")
  ) %>%
  tab_style(
    style = cell_fill(color = "#f8d7da"),
    locations = cells_body(rows = Metric == "Market Velocity" & Value == "Limited")
  )
```

**Data Validity Assessment:**

The analysis is based on **`r n_sales`** sales transactions occurring over **`r sprintf("%.1f", coverage_months)`** months. This provides `r if_else(coverage_months >= 3, "excellent", if_else(coverage_months >= 1.5, "adequate", "limited"))` market coverage for the subject property's market area.

---

# Reconciliation and Final Value Opinion

## Value Indications

```{r value-reconciliation}
#| label: value-reconciliation

# Calculate various value indicators
value_indicators <- tibble(
  Method = c(
    "Median Sale Price",
    "Mean Sale Price",
    "Price Per SF (Median × Subject SF)",
    "Price Per SF (Mean × Subject SF)",
    "Linear Regression (Trend-Adjusted)",
    "Machine Learning (Random Forest)",
    "Appraiser's Final Opinion"
  ),
  Value = c(
    median(sales_clean$sale_price),
    mean(sales_clean$sale_price),
    median(sales_clean$price_per_sf) * params$LivingArea,
    mean(sales_clean$price_per_sf) * params$LivingArea,
    # Trend-adjusted median (placeholder - would use actual trend calc)
    median(sales_clean$sale_price),
    # ML prediction (would come from Python)
    NA_real_,
    params$EstimatedValue
  ),
  Weight = c(
    "Reference",
    "Reference",
    "Moderate",
    "Moderate",
    "Significant",
    "Supporting",
    "Primary"
  )
)

value_indicators %>%
  gt() %>%
  tab_header(
    title = "Value Indication Reconciliation"
  ) %>%
  fmt_currency(
    columns = Value,
    decimals = 0
  ) %>%
  cols_label(
    Method = "Valuation Method",
    Value = "Indicated Value",
    Weight = "Weight"
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#d4edda"),
      cell_text(weight = "bold")
    ),
    locations = cells_body(rows = Method == "Appraiser's Final Opinion")
  )
```

## Narrative Conclusion

Based on the comprehensive statistical analysis of **`r n_sales`** comparable sales in the subject's market area, the following conclusions are drawn:

1. **Market Trend**: The market exhibits a `r if_else(monthly_change_pct > 1, "positive", if_else(monthly_change_pct < -1, "negative", "stable"))` trend with approximately **`r sprintf("%.2f%%", abs(monthly_change_pct))`** monthly price change.

2. **Price Distribution**: The median sale price of **`r dollar(median(sales_clean$sale_price))`** and mean of **`r dollar(mean(sales_clean$sale_price))`** provide strong central tendency measures.

3. **Price Per Square Foot**: Market data indicates a median of **`r dollar(median(sales_clean$price_per_sf))`** per SF and mean of **`r dollar(mean(sales_clean$price_per_sf))`** per SF.

4. **Subject Positioning**: The subject property's characteristics align well with the market sample, falling within the typical range for living area, age, and condition.

5. **Statistical Confidence**: The regression analysis shows R² = **`r sprintf("%.4f", r_value**2)`**, indicating `r if_else(r_value**2 > 0.7, "strong", if_else(r_value**2 > 0.4, "moderate", "weak"))` correlation between time and price.

**Therefore, considering all evidence and giving primary weight to the trend-adjusted statistical analysis, the opinion of market value for the subject property as of `r params$DateEffective` is:**

<center>
<h2 style="color: #2c3e50; background-color: #ecf0f1; padding: 20px; border-radius: 10px;">
**`r dollar(params$EstimatedValue)`**
</h2>
</center>

**Value Range:** `r dollar(params$ValueRangeLow)` to `r dollar(params$ValueRangeHigh)`

---

# Certification

I certify that, to the best of my knowledge and belief:

- The statements of fact contained in this report are true and correct
- The reported analyses, opinions, and conclusions are limited only by the assumptions and limiting conditions
- I have no present or prospective interest in the property that is the subject of this report
- I have performed no services regarding the subject property within the three-year period immediately preceding acceptance of this assignment
- The reported analyses, opinions, and conclusions were developed in conformity with the requirements of USPAP
- This appraisal assignment was not based on a requested minimum valuation or specific valuation
- The analyses, opinions, and conclusions in this report are my own unbiased professional analyses, opinions, and conclusions

**Appraiser:** `r params$AppraiserName`

**File Number:** `r params$FileNumber`

**Date of Report:** `r format(Sys.Date(), '%B %d, %Y')`

---

# Appendix: Methodology References

## Evidence-Based Valuation (EBV)

This report employs Evidence-Based Valuation methodology as described by Kyle Pacquin, which emphasizes:

- Analysis of the entire market population rather than selective sampling
- Statistical rigor through regression analysis and confidence intervals
- Transparent data coverage metrics
- Visual analytics for clear communication
- Machine learning validation using Random Forest and other algorithms

## Statistical Methods

- **Linear Regression**: Ordinary least squares to quantify price trends over time
- **Correlation Analysis**: R² values to measure strength of relationships
- **Distribution Analysis**: Histograms, box plots, and summary statistics
- **Time Series Analysis**: Monthly absorption rates and trend identification
- **Machine Learning**: Random Forest regression for predictive validation

## Data Sources

- MLS data export: `r params$DataFile`
- Configuration file: `r params$ConfigFile`
- Validation results: `r params$ValidationFile`

---

*End of Report*
